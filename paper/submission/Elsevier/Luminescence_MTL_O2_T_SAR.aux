\relax 
\Newlabel{cor1}{1}
\citation{Stich2010,Borisov2011novel,Kameya2014,Wang2014,Santoro2016,Biring2019}
\citation{Wang2014,Biring2019,Collier2013,Stehning2004,Jorge2008,Moore2006}
\citation{Papkovsky2013,Wang2014}
\citation{Lakowicz2006}
\citation{Li2015}
\citation{Xu1994,Draxler1995,Hartmann1996,Mills1998,Badocco2008,Dini2011}
\citation{Argyriou2006,Thrun1996,Caruana1997,Zhang2017,Baxter2000,Thung2018}
\citation{Michelucci2019_2}
\Newlabel{zhaw}{a}
\Newlabel{toelt}{b}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}\protected@file@percent }
\newlabel{Introduction}{{1}{1}}
\@LN@col{2}
\citation{Michelucci2019_2}
\citation{Lakowicz2006}
\citation{Wang2014}
\citation{Carraway1991,Demas1995}
\citation{Demas1995,Hartmann1995,Mills1999}
\citation{Wei2019}
\citation{Demas1995,Quaranta2012}
\citation{Michelucci2019}
\citation{Ogurtsov2006,lo2008,Zaitsev2016}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}\protected@file@percent }
\newlabel{sec:methods}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Luminescence Quenching for Oxygen Determination}{2}\protected@file@percent }
\newlabel{Theory}{{2.1}{2}}
\@LN@col{2}
\newlabel{SVe}{{1}{2}}
\newlabel{SVe2}{{2}{2}}
\newlabel{theta_full}{{3}{2}}
\citation{Michelucci2017}
\citation{Michelucci2019_2}
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Schematic diagram of the experimental setup. Blue indicates the excitation optical path, red the luminescence one. SP: shortpass filter; LP: longpass filter PD: photodiode; TIA: trans-impedance amplifier.}}{3}\protected@file@percent }
\newlabel{fig:setup}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Experimental Procedure}{3}\protected@file@percent }
\newlabel{Experimental}{{2.2}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Experimental Setup}{3}\protected@file@percent }
\@LN@col{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Automated Data Acquisition}{3}\protected@file@percent }
\newlabel{Data}{{2.2.2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Neural Network Approach}{3}\protected@file@percent }
\newlabel{NN}{{2.3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Neural Network Architecture}{3}\protected@file@percent }
\@LN@col{1}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Flow-chart of the automated data acquisition program.}}{4}\protected@file@percent }
\newlabel{fig:auto-data}{{2}{4}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture of the multi-task learning neural network used in this paper. The common hidden layers generate a "shared representation" as output, that is used as input to task specific branches that learn specific features to each quantity and therefore improve the prediction accuracy. $L_i$ are the task-specific loss functions; $[O_2]_{i,pred}$ and $T_{i,pred}$ are the oxygen concentration and temperature predictions of the corresponding branch $i$. Note that branch 2 and 3 have only one output.}}{4}\protected@file@percent }
\newlabel{fig:NN_MTL_O2_T}{{3}{4}}
\newlabel{input1}{{4}{4}}
\newlabel{input2}{{5}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Loss Function}{4}\protected@file@percent }
\newlabel{MSE}{{6}{4}}
\citation{Michelucci2019_2}
\citation{Kingma2014,Michelucci2017}
\citation{Michelucci2017}
\citation{Hastie2009}
\citation{Sain1996}
\citation{Waskom2020}
\@LN@col{1}
\newlabel{globalcf}{{7}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Optimiser Algorithm}{5}\protected@file@percent }
\newlabel{training}{{2.3.3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Performance Evaluation}{5}\protected@file@percent }
\@LN@col{2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Absolute Error on the Prediction}{5}\protected@file@percent }
\newlabel{AE}{{9}{5}}
\newlabel{MAE}{{10}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Kernel Density Estimation}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Error Limited Accuracy $\eta $}{5}\protected@file@percent }
\newlabel{sektion:ela}{{2.4.3}{5}}
\@LN@col{1}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results and Discussion}{6}\protected@file@percent }
\newlabel{Results}{{3}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Luminescence Experimental Results}{6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Measured phase shift as a function of the oxygen concentration for selected temperatures at a fixed modulation frequency of 6 kHz. The arrow marks increasing temperatures.}}{6}\protected@file@percent }
\newlabel{fig:expdata1}{{4}{6}}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Measured phase shift as a function of the modulation frequency for selected temperatures at a fixed oxygen concentration of $[O_2]=20 \ \%$ air. The arrow marks increasing temperatures.}}{6}\protected@file@percent }
\newlabel{fig:expdata2}{{5}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Measured phase shift as a function of the modulation frequency for selected oxygen concentrations at a fixed temperature of $T=25 \ ^{\circ }$C. The arrow marks increasing oxygen concentrations.}}{6}\protected@file@percent }
\newlabel{fig:expdata3}{{6}{6}}
\@LN@col{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sensor performance}{7}\protected@file@percent }
\@LN@col{2}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \bf  Summary of the performance for neural network models}}{7}\protected@file@percent }
\newlabel{TableMAE_summary}{{1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Error Limited Accuracy}{7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Distributions of the neural network predictions for the oxygen concentration (panels (A), (C) and (E)) and for the temperature (panels (B), (D) and (F)). In all panels the normalized prediction distribution histogram (columns), the kernel density estimate (KDE) of the distribution of the $AE$s (solid line), and $MAE$ (dashed vertical line) are shown. Panels (A) and (B): Comparison between training using no batches (NB) and using mini-batches (MB) with a batch size of 32 for 20'000 epochs; the input of the network is ${\pmb  \theta }_s$. Panels (C) and (D): Comparison between training using mini-batches (MB) with a batch size of 32 for 100'000 and 20'000 epochs; the input of the network is ${\pmb  \theta }_s$. Panels (E) and (F): training using mini-batches (MB) with a batch size of 32 for 20'000 epochs; the input of the network is ${\pmb  \theta }_n$.}}{8}\protected@file@percent }
\newlabel{fig:KDE_results_all}{{7}{8}}
\citation{transfer}
\bibstyle{elsarticle-num-names}
\bibdata{bibliography.bib}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Comparison of the ELA $\eta $: Panel (A) oxygen prediction, panel (B) temperature prediction. The black lines are the results obtained with a network that was trained with ${\pmb  \theta }_n$ as input for 20'000 epochs with mini-batchs of size 32, while the red ones with ${\pmb  \theta }_s$ as input for 100'000 epochs with mini-batchs of size 32. The dashed lines indicates the values of the $\overline  {AE}$ for which the predictions would give $\eta =1$.}}{9}\protected@file@percent }
\newlabel{fig:ELA_result_comparison}{{8}{9}}
\@LN@col{1}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \bf  Summary of the values of $\overline  {AE}$ for the cases shown in Fig. 8\hbox {}(A) and 8\hbox {}(B).}}{9}\protected@file@percent }
\newlabel{table:ela}{{2}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions}{9}\protected@file@percent }
\@LN@col{2}
