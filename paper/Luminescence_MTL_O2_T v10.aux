\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{osajnl}
\babel@aux{english}{}
\citation{Stich2010,Borisov2011novel,Kameya2014,Wang2014,Santoro2016,Biring2019}
\citation{Collier2013,Wang2014,Stehning2004,Jorge2008,Biring2019,Moore2006}
\citation{Papkovsky2013,Wang2014}
\citation{Lakowicz2006}
\citation{Li2015}
\citation{Xu1994,Draxler1995,Hartmann1996,Mills1998,Badocco2008,Dini2011}
\citation{Argyriou2006,Thrun1996,Caruana1997,Zhang2017,Baxter2000,Thung2018}
\citation{Michelucci2019_2}
\citation{Lakowicz2006}
\citation{Wang2014}
\citation{Carraway1991,Demas1995}
\citation{Demas1995,Hartmann1995,Mills1999}
\citation{Wei2019}
\citation{Demas1995,Quaranta2012}
\citation{Michelucci2019}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{2}{section.2}}
\newlabel{sec:methods}{{2}{2}{Methods}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Luminescence Quenching for Oxygen Determination}{2}{subsection.2.1}}
\newlabel{Theory}{{A}{2}{Luminescence Quenching for Oxygen Determination}{subsection.2.1}{}}
\newlabel{SVe}{{1}{2}{Luminescence Quenching for Oxygen Determination}{equation.2.1}{}}
\newlabel{SVe2}{{2}{2}{Luminescence Quenching for Oxygen Determination}{equation.2.2}{}}
\citation{Ogurtsov2006,lo2008,Zaitsev2016}
\citation{Michelucci2017}
\citation{Michelucci2019_2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Schematic diagram of the experimental setup. Blue indicates the excitation optical path, red the luminescence one. SP: shortpass filter; LP: longpass filter PD: photodiode; TIA: trans-impedance amplifier.\relax }}{3}{figure.caption.1}}
\@cons\caption@pkg@list{{ragged2e}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:setup}{{1}{3}{Schematic diagram of the experimental setup. Blue indicates the excitation optical path, red the luminescence one. SP: shortpass filter; LP: longpass filter PD: photodiode; TIA: trans-impedance amplifier.\relax }{figure.caption.1}{}}
\newlabel{theta_full}{{3}{3}{Luminescence Quenching for Oxygen Determination}{equation.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Experimental Procedure}{3}{subsection.2.2}}
\newlabel{Experimental}{{B}{3}{Experimental Procedure}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.1}Experimental Setup}{3}{subsubsection.2.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {B.2}Automated Data Acquisition}{3}{subsubsection.2.2.2}}
\newlabel{Data}{{B.2}{3}{Automated Data Acquisition}{subsubsection.2.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Neural Network Approach}{3}{subsection.2.3}}
\newlabel{NN}{{C}{3}{Neural Network Approach}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.1}Neural Network Architecture}{4}{subsubsection.2.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Flow-chart of the automated data acquisition program.\relax }}{4}{figure.caption.2}}
\newlabel{fig:auto-data}{{2}{4}{Flow-chart of the automated data acquisition program.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture of the multi-task learning neural network used in this paper. The common hidden layers generate as output a "shared representation" that is used as input to task specific branches that learn specific features to each quantity and therefore improve the prediction accuracy. $L_i$ are the task-specific loss functions; $[O_2]_{i,pred}$ and $T_{i,pred}$ are the oxygen concentration and temperature predictions of the corresponding branch $i$. Note that branch 2 and 3 have only one output.\relax }}{4}{figure.caption.3}}
\newlabel{fig:NN_MTL_O2_T}{{3}{4}{Architecture of the multi-task learning neural network used in this paper. The common hidden layers generate as output a "shared representation" that is used as input to task specific branches that learn specific features to each quantity and therefore improve the prediction accuracy. $L_i$ are the task-specific loss functions; $[O_2]_{i,pred}$ and $T_{i,pred}$ are the oxygen concentration and temperature predictions of the corresponding branch $i$. Note that branch 2 and 3 have only one output.\relax }{figure.caption.3}{}}
\newlabel{input1}{{4}{4}{Neural Network Architecture}{equation.2.4}{}}
\newlabel{input2}{{5}{4}{Neural Network Architecture}{equation.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.2}Loss Function}{4}{subsubsection.2.3.2}}
\newlabel{MSE}{{6}{4}{Loss Function}{equation.2.6}{}}
\citation{Michelucci2019_2}
\citation{Kingma2014,Michelucci2017}
\citation{Michelucci2017}
\citation{Hastie2009}
\citation{Sain1996}
\citation{Waskom2020}
\newlabel{globalcf}{{7}{5}{Loss Function}{equation.2.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.3}Optimiser Algorithm}{5}{subsubsection.2.3.3}}
\newlabel{training}{{C.3}{5}{Optimiser Algorithm}{subsubsection.2.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Performance Evaluation}{5}{subsection.2.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.1}Absolute Error on the Prediction}{5}{subsubsection.2.4.1}}
\newlabel{AE}{{9}{5}{Absolute Error on the Prediction}{equation.2.9}{}}
\newlabel{MAE}{{10}{5}{Absolute Error on the Prediction}{equation.2.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.2}Kernel Density Estimation}{5}{subsubsection.2.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {D.3}Error Limited Accuracy $\eta $}{5}{subsubsection.2.4.3}}
\newlabel{sektion:ela}{{D.3}{5}{Error Limited Accuracy $\eta $}{subsubsection.2.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results and Discussion}{6}{section.3}}
\newlabel{Results}{{3}{6}{Results and Discussion}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Luminescence Experimental Results}{6}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Measured phase shift as a function of the oxygen concentration for selected temperatures at a fixed modulation frequency of 6 kHz. The arrow marks increasing temperatures.\relax }}{6}{figure.caption.4}}
\newlabel{fig:expdata1}{{4}{6}{Measured phase shift as a function of the oxygen concentration for selected temperatures at a fixed modulation frequency of 6 kHz. The arrow marks increasing temperatures.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Measured phase shift as a function of the modulation frequency for selected temperatures at a fixed oxygen concentration of $[O_2]=20 \%$. The arrow marks increasing temperatures.\relax }}{6}{figure.caption.5}}
\newlabel{fig:expdata2}{{5}{6}{Measured phase shift as a function of the modulation frequency for selected temperatures at a fixed oxygen concentration of $[O_2]=20 \%$. The arrow marks increasing temperatures.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Measured phase shift as a function of the modulation frequency for selected oxygen concentrations at a fixed temperature of $T=25 ^{\circ }$C. The arrow marks increasing oxygen concentrations.\relax }}{6}{figure.caption.6}}
\newlabel{fig:expdata3}{{6}{6}{Measured phase shift as a function of the modulation frequency for selected oxygen concentrations at a fixed temperature of $T=25 ^{\circ }$C. The arrow marks increasing oxygen concentrations.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Sensor performance}{6}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Performance of the neural network for the oxygen (panels (A), (C) and (E)) and for the temperature (panels (B), (D) and (F)) predictions. In all panels the normalized prediction distribution histogram (columns), the kernel density estimate (KDE) of the distribution of the $AE$s (solid line), and $MAE$ (dashed vertical line) are shown. Panels (A) and (B): Comparison between training using no batches (NB) and using mini-batches (MB) with a batch size of 32 for 20'000 epochs; the input of the network is ${\pmb  \theta }_s$. Panels (C) and (D): Comparison between training using mini-batches (MB) with a batch size of 32 for 100'000 and 20'000 epochs; the input of the network is ${\pmb  \theta }_s$. Panels (E) and (F): training using mini-batches (MB) with a batch size of 32 for 20'000 epochs; the input of the network is ${\pmb  \theta }_n$.\relax }}{7}{figure.caption.7}}
\newlabel{fig:KDE_results_all}{{7}{7}{Performance of the neural network for the oxygen (panels (A), (C) and (E)) and for the temperature (panels (B), (D) and (F)) predictions. In all panels the normalized prediction distribution histogram (columns), the kernel density estimate (KDE) of the distribution of the $AE$s (solid line), and $MAE$ (dashed vertical line) are shown. Panels (A) and (B): Comparison between training using no batches (NB) and using mini-batches (MB) with a batch size of 32 for 20'000 epochs; the input of the network is ${\pmb \theta }_s$. Panels (C) and (D): Comparison between training using mini-batches (MB) with a batch size of 32 for 100'000 and 20'000 epochs; the input of the network is ${\pmb \theta }_s$. Panels (E) and (F): training using mini-batches (MB) with a batch size of 32 for 20'000 epochs; the input of the network is ${\pmb \theta }_n$.\relax }{figure.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \bf  Summary of the performance for neural network models\relax }}{8}{table.caption.8}}
\newlabel{TableMAE_summary}{{1}{8}{\bf Summary of the performance for neural network models\relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Error Limited Accuracy Plots}{8}{subsection.3.3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \bf  Summary of the values of $\overline  {AE}$ for the cases shown in Fig. \ref  {fig:ELA_result_comparison}(A) and \ref  {fig:ELA_result_comparison}(B).\relax }}{8}{table.caption.10}}
\newlabel{table:ela}{{2}{8}{\bf Summary of the values of $\overline {AE}$ for the cases shown in Fig. \ref {fig:ELA_result_comparison}(A) and \ref {fig:ELA_result_comparison}(B).\relax }{table.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions}{8}{section.4}}
\bibdata{bibliography}
\bibcite{Stich2010}{{1}{}{{}}{{}}}
\bibcite{Borisov2011novel}{{2}{}{{}}{{}}}
\bibcite{Kameya2014}{{3}{}{{}}{{}}}
\bibcite{Wang2014}{{4}{}{{}}{{}}}
\bibcite{Santoro2016}{{5}{}{{}}{{}}}
\bibcite{Biring2019}{{6}{}{{}}{{}}}
\bibcite{Collier2013}{{7}{}{{}}{{}}}
\bibcite{Stehning2004}{{8}{}{{}}{{}}}
\bibcite{Jorge2008}{{9}{}{{}}{{}}}
\bibcite{Moore2006}{{10}{}{{}}{{}}}
\bibcite{Papkovsky2013}{{11}{}{{}}{{}}}
\bibcite{Lakowicz2006}{{12}{}{{}}{{}}}
\bibcite{Li2015}{{13}{}{{}}{{}}}
\bibcite{Xu1994}{{14}{}{{}}{{}}}
\bibcite{Draxler1995}{{15}{}{{}}{{}}}
\bibcite{Hartmann1996}{{16}{}{{}}{{}}}
\bibcite{Mills1998}{{17}{}{{}}{{}}}
\bibcite{Badocco2008}{{18}{}{{}}{{}}}
\bibcite{Dini2011}{{19}{}{{}}{{}}}
\bibcite{Argyriou2006}{{20}{}{{}}{{}}}
\bibcite{Thrun1996}{{21}{}{{}}{{}}}
\bibcite{Caruana1997}{{22}{}{{}}{{}}}
\bibcite{Zhang2017}{{23}{}{{}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Comparison of the ELA $\eta $: Panel (A) oxygen prediction, panel (B) temperature prediction. The black line are the results for the network that were trained with ${\pmb  \theta }_n$ as input for 20'000 epochs with mini-batchs of size 32, while the red one with ${\pmb  \theta }_s$ as input for 100'000 epochs with mini-batchs of size 32. The dashed lines indicates the values of the $\overline  {AE}$ for which the predictions would give $\eta =1$.\relax }}{9}{figure.caption.9}}
\newlabel{fig:ELA_result_comparison}{{8}{9}{Comparison of the ELA $\eta $: Panel (A) oxygen prediction, panel (B) temperature prediction. The black line are the results for the network that were trained with ${\pmb \theta }_n$ as input for 20'000 epochs with mini-batchs of size 32, while the red one with ${\pmb \theta }_s$ as input for 100'000 epochs with mini-batchs of size 32. The dashed lines indicates the values of the $\overline {AE}$ for which the predictions would give $\eta =1$.\relax }{figure.caption.9}{}}
\bibcite{Baxter2000}{{24}{}{{}}{{}}}
\bibcite{Thung2018}{{25}{}{{}}{{}}}
\bibcite{Michelucci2019_2}{{26}{}{{}}{{}}}
\bibcite{Carraway1991}{{27}{}{{}}{{}}}
\bibcite{Demas1995}{{28}{}{{}}{{}}}
\bibcite{Hartmann1995}{{29}{}{{}}{{}}}
\bibcite{Mills1999}{{30}{}{{}}{{}}}
\bibcite{Wei2019}{{31}{}{{}}{{}}}
\bibcite{Quaranta2012}{{32}{}{{}}{{}}}
\bibcite{Michelucci2019}{{33}{}{{}}{{}}}
\bibcite{Ogurtsov2006}{{34}{}{{}}{{}}}
\bibcite{lo2008}{{35}{}{{}}{{}}}
\bibcite{Zaitsev2016}{{36}{}{{}}{{}}}
\bibcite{Michelucci2017}{{37}{}{{}}{{}}}
\bibcite{Kingma2014}{{38}{}{{}}{{}}}
\bibcite{Hastie2009}{{39}{}{{}}{{}}}
\bibcite{Sain1996}{{40}{}{{}}{{}}}
\bibcite{Waskom2020}{{41}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\newlabel{LastPage}{{}{10}{}{page.10}{}}
\xdef\lastpage@lastpage{10}
\xdef\lastpage@lastpageHy{10}
